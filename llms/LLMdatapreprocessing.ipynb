{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8463029,"sourceType":"datasetVersion","datasetId":5045113}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/the-verdict/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n    \nprint(\"Total number of character:\", len(raw_text))\nprint(raw_text[:99])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:13:43.180830Z","iopub.execute_input":"2025-07-04T15:13:43.181135Z","iopub.status.idle":"2025-07-04T15:13:43.198547Z","shell.execute_reply.started":"2025-07-04T15:13:43.181110Z","shell.execute_reply":"2025-07-04T15:13:43.197322Z"}},"outputs":[{"name":"stdout","text":"Total number of character: 20479\nI HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\n\ntext = \"Hello, world. This, is a test.\"\nresult = re.split(r'(\\s)', text)\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:14:14.854380Z","iopub.execute_input":"2025-07-04T15:14:14.854775Z","iopub.status.idle":"2025-07-04T15:14:14.861271Z","shell.execute_reply.started":"2025-07-04T15:14:14.854750Z","shell.execute_reply":"2025-07-04T15:14:14.860010Z"}},"outputs":[{"name":"stdout","text":"['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"result = re.split(r'([,.]|\\s)', text)\n\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:14:42.973713Z","iopub.execute_input":"2025-07-04T15:14:42.974051Z","iopub.status.idle":"2025-07-04T15:14:42.981278Z","shell.execute_reply.started":"2025-07-04T15:14:42.974029Z","shell.execute_reply":"2025-07-04T15:14:42.979846Z"}},"outputs":[{"name":"stdout","text":"['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"result = [item for item in result if item.strip()]\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:15:04.651088Z","iopub.execute_input":"2025-07-04T15:15:04.652914Z","iopub.status.idle":"2025-07-04T15:15:04.659107Z","shell.execute_reply.started":"2025-07-04T15:15:04.652861Z","shell.execute_reply":"2025-07-04T15:15:04.657808Z"}},"outputs":[{"name":"stdout","text":"['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"text = \"Hello, world. Is this-- a test?\"\nresult = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\nresult = [item.strip() for item in result if item.strip()]\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:16:07.445733Z","iopub.execute_input":"2025-07-04T15:16:07.446516Z","iopub.status.idle":"2025-07-04T15:16:07.453267Z","shell.execute_reply.started":"2025-07-04T15:16:07.446485Z","shell.execute_reply":"2025-07-04T15:16:07.451814Z"}},"outputs":[{"name":"stdout","text":"['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\npreprocessed = [item.strip() for item in preprocessed if item.strip()]\nprint(preprocessed[:30])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:16:54.002064Z","iopub.execute_input":"2025-07-04T15:16:54.002467Z","iopub.status.idle":"2025-07-04T15:16:54.013410Z","shell.execute_reply.started":"2025-07-04T15:16:54.002434Z","shell.execute_reply":"2025-07-04T15:16:54.012069Z"}},"outputs":[{"name":"stdout","text":"['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(len(preprocessed))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:17:26.318084Z","iopub.execute_input":"2025-07-04T15:17:26.318382Z","iopub.status.idle":"2025-07-04T15:17:26.324404Z","shell.execute_reply.started":"2025-07-04T15:17:26.318360Z","shell.execute_reply":"2025-07-04T15:17:26.323215Z"}},"outputs":[{"name":"stdout","text":"4690\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"all_words = sorted(set(preprocessed))\nvocab_size = len(all_words)\n\nprint(vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:21:01.270771Z","iopub.execute_input":"2025-07-04T15:21:01.271075Z","iopub.status.idle":"2025-07-04T15:21:01.278373Z","shell.execute_reply.started":"2025-07-04T15:21:01.271055Z","shell.execute_reply":"2025-07-04T15:21:01.276975Z"}},"outputs":[{"name":"stdout","text":"1130\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"vocab = {token:integer for integer,token in enumerate(all_words)}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:21:54.023690Z","iopub.execute_input":"2025-07-04T15:21:54.023995Z","iopub.status.idle":"2025-07-04T15:21:54.030713Z","shell.execute_reply.started":"2025-07-04T15:21:54.023975Z","shell.execute_reply":"2025-07-04T15:21:54.029462Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for i, item in enumerate(vocab.items()):\n    print(item)\n    if i >= 50:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:22:30.128850Z","iopub.execute_input":"2025-07-04T15:22:30.129173Z","iopub.status.idle":"2025-07-04T15:22:30.137091Z","shell.execute_reply.started":"2025-07-04T15:22:30.129153Z","shell.execute_reply":"2025-07-04T15:22:30.135354Z"}},"outputs":[{"name":"stdout","text":"('!', 0)\n('\"', 1)\n(\"'\", 2)\n('(', 3)\n(')', 4)\n(',', 5)\n('--', 6)\n('.', 7)\n(':', 8)\n(';', 9)\n('?', 10)\n('A', 11)\n('Ah', 12)\n('Among', 13)\n('And', 14)\n('Are', 15)\n('Arrt', 16)\n('As', 17)\n('At', 18)\n('Be', 19)\n('Begin', 20)\n('Burlington', 21)\n('But', 22)\n('By', 23)\n('Carlo', 24)\n('Chicago', 25)\n('Claude', 26)\n('Come', 27)\n('Croft', 28)\n('Destroyed', 29)\n('Devonshire', 30)\n('Don', 31)\n('Dubarry', 32)\n('Emperors', 33)\n('Florence', 34)\n('For', 35)\n('Gallery', 36)\n('Gideon', 37)\n('Gisburn', 38)\n('Gisburns', 39)\n('Grafton', 40)\n('Greek', 41)\n('Grindle', 42)\n('Grindles', 43)\n('HAD', 44)\n('Had', 45)\n('Hang', 46)\n('Has', 47)\n('He', 48)\n('Her', 49)\n('Hermia', 50)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"class SimpleTokenizerV1:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = {i:s for s,i in vocab.items()}\n    \n    def encode(self, text):\n        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n                                \n        preprocessed = [\n            item.strip() for item in preprocessed if item.strip()\n        ]\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n        \n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # Replace spaces before the specified punctuations\n        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n        return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:22:50.361335Z","iopub.execute_input":"2025-07-04T15:22:50.361692Z","iopub.status.idle":"2025-07-04T15:22:50.369746Z","shell.execute_reply.started":"2025-07-04T15:22:50.361668Z","shell.execute_reply":"2025-07-04T15:22:50.368625Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV1(vocab)\n\ntext = \"\"\"\"It's the last he painted, you know,\" \n           Mrs. Gisburn said with pardonable pride.\"\"\"\nids = tokenizer.encode(text)\nprint(ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:24:25.927765Z","iopub.execute_input":"2025-07-04T15:24:25.928839Z","iopub.status.idle":"2025-07-04T15:24:25.934531Z","shell.execute_reply.started":"2025-07-04T15:24:25.928808Z","shell.execute_reply":"2025-07-04T15:24:25.933498Z"}},"outputs":[{"name":"stdout","text":"[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"tokenizer.decode(ids)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:25:03.044224Z","iopub.execute_input":"2025-07-04T15:25:03.044508Z","iopub.status.idle":"2025-07-04T15:25:03.052970Z","shell.execute_reply.started":"2025-07-04T15:25:03.044488Z","shell.execute_reply":"2025-07-04T15:25:03.051661Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"text = \"Hello, do you like tea?\"\nprint(tokenizer.encode(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:25:21.578039Z","iopub.execute_input":"2025-07-04T15:25:21.578366Z","iopub.status.idle":"2025-07-04T15:25:21.672154Z","shell.execute_reply.started":"2025-07-04T15:25:21.578344Z","shell.execute_reply":"2025-07-04T15:25:21.670949Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1763555282.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hello, do you like tea?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/2118097954.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/2118097954.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Hello'"],"ename":"KeyError","evalue":"'Hello'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"all_tokens = sorted(list(set(preprocessed)))\nall_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n\nvocab = {token:integer for integer,token in enumerate(all_tokens)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:26:21.295134Z","iopub.execute_input":"2025-07-04T15:26:21.295440Z","iopub.status.idle":"2025-07-04T15:26:21.302375Z","shell.execute_reply.started":"2025-07-04T15:26:21.295418Z","shell.execute_reply":"2025-07-04T15:26:21.301067Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"len(vocab.items())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:26:34.934313Z","iopub.execute_input":"2025-07-04T15:26:34.934804Z","iopub.status.idle":"2025-07-04T15:26:34.941935Z","shell.execute_reply.started":"2025-07-04T15:26:34.934641Z","shell.execute_reply":"2025-07-04T15:26:34.940746Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"1132"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"for i, item in enumerate(list(vocab.items())[-5:]):\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:26:49.536664Z","iopub.execute_input":"2025-07-04T15:26:49.536982Z","iopub.status.idle":"2025-07-04T15:26:49.543412Z","shell.execute_reply.started":"2025-07-04T15:26:49.536959Z","shell.execute_reply":"2025-07-04T15:26:49.542389Z"}},"outputs":[{"name":"stdout","text":"('younger', 1127)\n('your', 1128)\n('yourself', 1129)\n('<|endoftext|>', 1130)\n('<|unk|>', 1131)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"class SimpleTokenizerV2:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = { i:s for s,i in vocab.items()}\n    \n    def encode(self, text):\n        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n        preprocessed = [\n            item if item in self.str_to_int \n            else \"<|unk|>\" for item in preprocessed\n        ]\n\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n        \n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # Replace spaces before the specified punctuations\n        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n        return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:28:06.205042Z","iopub.execute_input":"2025-07-04T15:28:06.205359Z","iopub.status.idle":"2025-07-04T15:28:06.213341Z","shell.execute_reply.started":"2025-07-04T15:28:06.205339Z","shell.execute_reply":"2025-07-04T15:28:06.212035Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV2(vocab)\n\ntext1 = \"Hello, do you like tea?\"\ntext2 = \"In the sunlit terraces of the palace.\"\n\ntext = \" <|endoftext|> \".join((text1, text2))\n\nprint(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:28:41.673964Z","iopub.execute_input":"2025-07-04T15:28:41.674257Z","iopub.status.idle":"2025-07-04T15:28:41.680531Z","shell.execute_reply.started":"2025-07-04T15:28:41.674237Z","shell.execute_reply":"2025-07-04T15:28:41.679594Z"}},"outputs":[{"name":"stdout","text":"Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"tokenizer.encode(text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:29:03.565699Z","iopub.execute_input":"2025-07-04T15:29:03.566066Z","iopub.status.idle":"2025-07-04T15:29:03.573468Z","shell.execute_reply.started":"2025-07-04T15:29:03.566043Z","shell.execute_reply":"2025-07-04T15:29:03.572535Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"tokenizer.decode(tokenizer.encode(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:29:41.686276Z","iopub.execute_input":"2025-07-04T15:29:41.686643Z","iopub.status.idle":"2025-07-04T15:29:41.693649Z","shell.execute_reply.started":"2025-07-04T15:29:41.686618Z","shell.execute_reply":"2025-07-04T15:29:41.692482Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"! pip3 install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:35:00.370125Z","iopub.execute_input":"2025-07-04T15:35:00.370457Z","iopub.status.idle":"2025-07-04T15:35:05.991286Z","shell.execute_reply.started":"2025-07-04T15:35:00.370434Z","shell.execute_reply":"2025-07-04T15:35:05.989848Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import importlib\nimport tiktoken\n\nprint(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:35:31.819648Z","iopub.execute_input":"2025-07-04T15:35:31.819991Z","iopub.status.idle":"2025-07-04T15:35:31.947373Z","shell.execute_reply.started":"2025-07-04T15:35:31.819963Z","shell.execute_reply":"2025-07-04T15:35:31.946005Z"}},"outputs":[{"name":"stdout","text":"tiktoken version: 0.9.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:02:47.074037Z","iopub.execute_input":"2025-07-04T16:02:47.074360Z","iopub.status.idle":"2025-07-04T16:02:48.830036Z","shell.execute_reply.started":"2025-07-04T16:02:47.074337Z","shell.execute_reply":"2025-07-04T16:02:48.828498Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"text = (\n    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n     \"of someunknownPlace.\"\n)\n\nintegers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n\nprint(integers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:03:02.462754Z","iopub.execute_input":"2025-07-04T16:03:02.464544Z","iopub.status.idle":"2025-07-04T16:03:02.471972Z","shell.execute_reply.started":"2025-07-04T16:03:02.464499Z","shell.execute_reply":"2025-07-04T16:03:02.470452Z"}},"outputs":[{"name":"stdout","text":"[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"strings = tokenizer.decode(integers)\n\nprint(strings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:13:02.350957Z","iopub.execute_input":"2025-07-04T16:13:02.351298Z","iopub.status.idle":"2025-07-04T16:13:02.358297Z","shell.execute_reply.started":"2025-07-04T16:13:02.351276Z","shell.execute_reply":"2025-07-04T16:13:02.356490Z"}},"outputs":[{"name":"stdout","text":"Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"integers = tokenizer.encode(\"Akwirw ier\")\nprint(integers)\n\nstrings = tokenizer.decode(integers)\nprint(strings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:13:55.674069Z","iopub.execute_input":"2025-07-04T16:13:55.674726Z","iopub.status.idle":"2025-07-04T16:13:55.681390Z","shell.execute_reply.started":"2025-07-04T16:13:55.674701Z","shell.execute_reply":"2025-07-04T16:13:55.680137Z"}},"outputs":[{"name":"stdout","text":"[33901, 86, 343, 86, 220, 959]\nAkwirw ier\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import tiktoken\n\n# Initialize the encodings for GPT-2, GPT-3, and GPT-4\nencodings = {\n    \"gpt2\": tiktoken.get_encoding(\"gpt2\"),\n    \"gpt3\": tiktoken.get_encoding(\"p50k_base\"),  # Commonly associated with GPT-3 models\n    \"gpt4\": tiktoken.get_encoding(\"cl100k_base\")  # Used for GPT-4 and later versions\n}\n\n# Get the vocabulary size for each encoding\nvocab_sizes = {model: encoding.n_vocab for model, encoding in encodings.items()}\n\n# Print the vocabulary sizes\nfor model, size in vocab_sizes.items():\n    print(f\"The vocabulary size for {model.upper()} is: {size}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:14:08.087740Z","iopub.execute_input":"2025-07-04T16:14:08.088054Z","iopub.status.idle":"2025-07-04T16:14:09.909879Z","shell.execute_reply.started":"2025-07-04T16:14:08.088035Z","shell.execute_reply":"2025-07-04T16:14:09.908829Z"}},"outputs":[{"name":"stdout","text":"The vocabulary size for GPT2 is: 50257\nThe vocabulary size for GPT3 is: 50281\nThe vocabulary size for GPT4 is: 100277\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"with open(\"/kaggle/input/the-verdict/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()\n\nenc_text = tokenizer.encode(raw_text)\nprint(len(enc_text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:21:21.398319Z","iopub.execute_input":"2025-07-04T16:21:21.398651Z","iopub.status.idle":"2025-07-04T16:21:21.431748Z","shell.execute_reply.started":"2025-07-04T16:21:21.398626Z","shell.execute_reply":"2025-07-04T16:21:21.430757Z"}},"outputs":[{"name":"stdout","text":"5145\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"enc_sample = enc_text[50:]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:21:38.657598Z","iopub.execute_input":"2025-07-04T16:21:38.657936Z","iopub.status.idle":"2025-07-04T16:21:38.663481Z","shell.execute_reply.started":"2025-07-04T16:21:38.657913Z","shell.execute_reply":"2025-07-04T16:21:38.662521Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"context_size = 4 #length of the input\n#The context_size of 4 means that the model is trained to look at a sequence of 4 words (or tokens) \n#to predict the next word in the sequence. \n#The input x is the first 4 tokens [1, 2, 3, 4], and the target y is the next 4 tokens [2, 3, 4, 5]\n\nx = enc_sample[:context_size]\ny = enc_sample[1:context_size+1]\n\nprint(f\"x: {x}\")\nprint(f\"y:      {y}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:21:54.319586Z","iopub.execute_input":"2025-07-04T16:21:54.320427Z","iopub.status.idle":"2025-07-04T16:21:54.326972Z","shell.execute_reply.started":"2025-07-04T16:21:54.320396Z","shell.execute_reply":"2025-07-04T16:21:54.325654Z"}},"outputs":[{"name":"stdout","text":"x: [290, 4920, 2241, 287]\ny:      [4920, 2241, 287, 257]\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"for i in range(1, context_size+1):\n    context = enc_sample[:i]\n    desired = enc_sample[i]\n\n    print(context, \"---->\", desired)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:22:09.962727Z","iopub.execute_input":"2025-07-04T16:22:09.963106Z","iopub.status.idle":"2025-07-04T16:22:09.969431Z","shell.execute_reply.started":"2025-07-04T16:22:09.963083Z","shell.execute_reply":"2025-07-04T16:22:09.968307Z"}},"outputs":[{"name":"stdout","text":"[290] ----> 4920\n[290, 4920] ----> 2241\n[290, 4920, 2241] ----> 287\n[290, 4920, 2241, 287] ----> 257\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"for i in range(1, context_size+1):\n    context = enc_sample[:i]\n    desired = enc_sample[i]\n\n    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:22:26.948097Z","iopub.execute_input":"2025-07-04T16:22:26.948390Z","iopub.status.idle":"2025-07-04T16:22:26.956017Z","shell.execute_reply.started":"2025-07-04T16:22:26.948370Z","shell.execute_reply":"2025-07-04T16:22:26.954457Z"}},"outputs":[{"name":"stdout","text":" and ---->  established\n and established ---->  himself\n and established himself ---->  in\n and established himself in ---->  a\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:22:47.888223Z","iopub.execute_input":"2025-07-04T16:22:47.888955Z","iopub.status.idle":"2025-07-04T16:22:53.775665Z","shell.execute_reply.started":"2025-07-04T16:22:47.888925Z","shell.execute_reply":"2025-07-04T16:22:53.774719Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256, \n                         stride=128, shuffle=True, drop_last=True,\n                         num_workers=0):\n\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers\n    )\n\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:23:09.132501Z","iopub.execute_input":"2025-07-04T16:23:09.133058Z","iopub.status.idle":"2025-07-04T16:23:09.139513Z","shell.execute_reply.started":"2025-07-04T16:23:09.133033Z","shell.execute_reply":"2025-07-04T16:23:09.138358Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"with open(\"/kaggle/input/the-verdict/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n    raw_text = f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:23:42.701495Z","iopub.execute_input":"2025-07-04T16:23:42.701891Z","iopub.status.idle":"2025-07-04T16:23:42.710936Z","shell.execute_reply.started":"2025-07-04T16:23:42.701867Z","shell.execute_reply":"2025-07-04T16:23:42.709973Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import torch\nprint(\"PyTorch version:\", torch.__version__)\ndataloader = create_dataloader_v1(\n    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n)\n\ndata_iter = iter(dataloader)\nfirst_batch = next(data_iter)\nprint(first_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:23:59.873644Z","iopub.execute_input":"2025-07-04T16:23:59.874030Z","iopub.status.idle":"2025-07-04T16:24:00.025709Z","shell.execute_reply.started":"2025-07-04T16:23:59.874008Z","shell.execute_reply":"2025-07-04T16:24:00.024644Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.6.0+cu124\n[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"second_batch = next(data_iter)\nprint(second_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:24:15.827875Z","iopub.execute_input":"2025-07-04T16:24:15.828221Z","iopub.status.idle":"2025-07-04T16:24:15.836711Z","shell.execute_reply.started":"2025-07-04T16:24:15.828197Z","shell.execute_reply":"2025-07-04T16:24:15.835614Z"}},"outputs":[{"name":"stdout","text":"[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)\nprint(\"Inputs:\\n\", inputs)\nprint(\"\\nTargets:\\n\", targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:25:23.523327Z","iopub.execute_input":"2025-07-04T16:25:23.523843Z","iopub.status.idle":"2025-07-04T16:25:23.570846Z","shell.execute_reply.started":"2025-07-04T16:25:23.523806Z","shell.execute_reply":"2025-07-04T16:25:23.569496Z"}},"outputs":[{"name":"stdout","text":"Inputs:\n tensor([[   40,   367,  2885,  1464],\n        [ 1807,  3619,   402,   271],\n        [10899,  2138,   257,  7026],\n        [15632,   438,  2016,   257],\n        [  922,  5891,  1576,   438],\n        [  568,   340,   373,   645],\n        [ 1049,  5975,   284,   502],\n        [  284,  3285,   326,    11]])\n\nTargets:\n tensor([[  367,  2885,  1464,  1807],\n        [ 3619,   402,   271, 10899],\n        [ 2138,   257,  7026, 15632],\n        [  438,  2016,   257,   922],\n        [ 5891,  1576,   438,   568],\n        [  340,   373,   645,  1049],\n        [ 5975,   284,   502,   284],\n        [ 3285,   326,    11,   287]])\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"input_ids = torch.tensor([2, 3, 5, 1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:27:23.045785Z","iopub.execute_input":"2025-07-04T16:27:23.046196Z","iopub.status.idle":"2025-07-04T16:27:23.052679Z","shell.execute_reply.started":"2025-07-04T16:27:23.046170Z","shell.execute_reply":"2025-07-04T16:27:23.051611Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"vocab_size = 6\noutput_dim = 3\n\ntorch.manual_seed(123)\nembedding_layer = torch.nn.Embedding(vocab_size, output_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:27:34.939505Z","iopub.execute_input":"2025-07-04T16:27:34.939980Z","iopub.status.idle":"2025-07-04T16:27:34.955727Z","shell.execute_reply.started":"2025-07-04T16:27:34.939950Z","shell.execute_reply":"2025-07-04T16:27:34.954536Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"print(embedding_layer.weight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:27:58.093676Z","iopub.execute_input":"2025-07-04T16:27:58.094136Z","iopub.status.idle":"2025-07-04T16:27:58.152767Z","shell.execute_reply.started":"2025-07-04T16:27:58.094109Z","shell.execute_reply":"2025-07-04T16:27:58.151755Z"}},"outputs":[{"name":"stdout","text":"Parameter containing:\ntensor([[ 0.3374, -0.1778, -0.1690],\n        [ 0.9178,  1.5810,  1.3010],\n        [ 1.2753, -0.2010, -0.1606],\n        [-0.4015,  0.9666, -1.1481],\n        [-1.1589,  0.3255, -0.6315],\n        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"print(embedding_layer(torch.tensor([3])))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:28:35.524347Z","iopub.execute_input":"2025-07-04T16:28:35.524691Z","iopub.status.idle":"2025-07-04T16:28:35.544508Z","shell.execute_reply.started":"2025-07-04T16:28:35.524666Z","shell.execute_reply":"2025-07-04T16:28:35.543341Z"}},"outputs":[{"name":"stdout","text":"tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print(embedding_layer(input_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:28:48.891291Z","iopub.execute_input":"2025-07-04T16:28:48.891863Z","iopub.status.idle":"2025-07-04T16:28:48.900896Z","shell.execute_reply.started":"2025-07-04T16:28:48.891825Z","shell.execute_reply":"2025-07-04T16:28:48.899687Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 1.2753, -0.2010, -0.1606],\n        [-0.4015,  0.9666, -1.1481],\n        [-2.8400, -0.7849, -1.4096],\n        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"vocab_size = 50257\noutput_dim = 256\n\ntoken_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:29:25.141694Z","iopub.execute_input":"2025-07-04T16:29:25.142101Z","iopub.status.idle":"2025-07-04T16:29:25.279853Z","shell.execute_reply.started":"2025-07-04T16:29:25.142073Z","shell.execute_reply":"2025-07-04T16:29:25.278914Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"max_length = 4\ndataloader = create_dataloader_v1(\n    raw_text, batch_size=8, max_length=max_length,\n    stride=max_length, shuffle=False\n)\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:30:05.122721Z","iopub.execute_input":"2025-07-04T16:30:05.123068Z","iopub.status.idle":"2025-07-04T16:30:05.293647Z","shell.execute_reply.started":"2025-07-04T16:30:05.123046Z","shell.execute_reply":"2025-07-04T16:30:05.292042Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"print(\"Token IDs:\\n\", inputs)\nprint(\"\\nInputs shape:\\n\", inputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:30:17.562138Z","iopub.execute_input":"2025-07-04T16:30:17.562485Z","iopub.status.idle":"2025-07-04T16:30:17.569958Z","shell.execute_reply.started":"2025-07-04T16:30:17.562463Z","shell.execute_reply":"2025-07-04T16:30:17.568457Z"}},"outputs":[{"name":"stdout","text":"Token IDs:\n tensor([[   40,   367,  2885,  1464],\n        [ 1807,  3619,   402,   271],\n        [10899,  2138,   257,  7026],\n        [15632,   438,  2016,   257],\n        [  922,  5891,  1576,   438],\n        [  568,   340,   373,   645],\n        [ 1049,  5975,   284,   502],\n        [  284,  3285,   326,    11]])\n\nInputs shape:\n torch.Size([8, 4])\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"token_embeddings = token_embedding_layer(inputs)\nprint(token_embeddings.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:30:31.837731Z","iopub.execute_input":"2025-07-04T16:30:31.838045Z","iopub.status.idle":"2025-07-04T16:30:31.844608Z","shell.execute_reply.started":"2025-07-04T16:30:31.838026Z","shell.execute_reply":"2025-07-04T16:30:31.842899Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 4, 256])\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"context_length = max_length\npos_embedding_layer = torch.nn.Embedding(context_length, output_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:30:49.954316Z","iopub.execute_input":"2025-07-04T16:30:49.954726Z","iopub.status.idle":"2025-07-04T16:30:49.960982Z","shell.execute_reply.started":"2025-07-04T16:30:49.954699Z","shell.execute_reply":"2025-07-04T16:30:49.959971Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"pos_embeddings = pos_embedding_layer(torch.arange(max_length))\nprint(pos_embeddings.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:31:01.763610Z","iopub.execute_input":"2025-07-04T16:31:01.764040Z","iopub.status.idle":"2025-07-04T16:31:01.771900Z","shell.execute_reply.started":"2025-07-04T16:31:01.764007Z","shell.execute_reply":"2025-07-04T16:31:01.770598Z"}},"outputs":[{"name":"stdout","text":"torch.Size([4, 256])\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"input_embeddings = token_embeddings + pos_embeddings\nprint(input_embeddings.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T16:31:26.999607Z","iopub.execute_input":"2025-07-04T16:31:27.000002Z","iopub.status.idle":"2025-07-04T16:31:27.007928Z","shell.execute_reply.started":"2025-07-04T16:31:26.999978Z","shell.execute_reply":"2025-07-04T16:31:27.006971Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 4, 256])\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}