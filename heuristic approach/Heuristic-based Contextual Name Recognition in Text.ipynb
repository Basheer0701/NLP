{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport string\n\n# Sample input\ntext = \"Barack Obama and Angela Merkel met in Berlin for the G20 Summit organized by the United Nations.\"\n\n# Tokenization: simple split and strip punctuation\ndef tokenize(text):\n    tokens = re.findall(r\"\\b\\w+(?:-\\w+)*\\b\", text)\n    return tokens\n\ntokens = tokenize(text)\nprint(tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:42:35.758234Z","iopub.execute_input":"2025-05-25T13:42:35.758502Z","iopub.status.idle":"2025-05-25T13:42:35.770201Z","shell.execute_reply.started":"2025-05-25T13:42:35.758469Z","shell.execute_reply":"2025-05-25T13:42:35.768791Z"}},"outputs":[{"name":"stdout","text":"['Barack', 'Obama', 'and', 'Angela', 'Merkel', 'met', 'in', 'Berlin', 'for', 'the', 'G20', 'Summit', 'organized', 'by', 'the', 'United', 'Nations']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Example sets - replace these with your loaded sets\nfirst_names = {\"Barack\", \"Angela\", \"John\", \"Narendra\", \"Michael\"}\nlast_names = {\"Obama\", \"Merkel\", \"Smith\", \"Modi\", \"Johnson\"}\nstopwords = {\"and\", \"the\", \"in\", \"for\", \"by\", \"of\", \"on\", \"at\", \"a\", \"an\"}\n\ndef classify_token(token):\n    if token.lower() in (w.lower() for w in stopwords):\n        return \"Stopword\"\n    elif token in first_names:\n        return \"First Name\"\n    elif token in last_names:\n        return \"Last Name\"\n    else:\n        return \"Other\"\n\n# Apply classification\nclassified_tokens = [(token, classify_token(token)) for token in tokens]\nfor token, classification in classified_tokens:\n    print(f\"{token}: {classification}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:45:21.354128Z","iopub.execute_input":"2025-05-25T13:45:21.355365Z","iopub.status.idle":"2025-05-25T13:45:21.363934Z","shell.execute_reply.started":"2025-05-25T13:45:21.355324Z","shell.execute_reply":"2025-05-25T13:45:21.362606Z"}},"outputs":[{"name":"stdout","text":"Barack: First Name\nObama: Last Name\nand: Stopword\nAngela: First Name\nMerkel: Last Name\nmet: Other\nin: Stopword\nBerlin: Other\nfor: Stopword\nthe: Stopword\nG20: Other\nSummit: Other\norganized: Other\nby: Stopword\nthe: Stopword\nUnited: Other\nNations: Other\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def name_recognition_with_context(tokens, first_names, last_names, stopwords):\n    def classify_token(token):\n        if token in first_names:\n            return 'First Name'\n        elif token in last_names:\n            return 'Last Name'\n        elif token.lower() in stopwords:\n            return 'Stopword'\n        else:\n            return 'Other'\n\n    # Step 1: Initial classification\n    classifications = [classify_token(t) for t in tokens]\n\n    # Step 2: Context-aware adjustment\n    adjusted = classifications.copy()\n    for i, token in enumerate(tokens):\n        if classifications[i] == 'Other' and token[0].isupper():\n            neighbors = []\n            if i > 0:\n                neighbors.append(classifications[i-1])\n            if i < len(tokens) - 1:\n                neighbors.append(classifications[i+1])\n\n            if 'First Name' in neighbors or 'Last Name' in neighbors:\n                adjusted[i] = 'Possible Name'\n\n    # Step 3: Multi-word name detection\n    name_labels = {'First Name', 'Last Name', 'Possible Name'}\n    multiword_names = []\n    current_chunk = []\n\n    for token, label in zip(tokens, adjusted):\n        if label in name_labels:\n            current_chunk.append(token)\n        else:\n            if len(current_chunk) > 1:\n                multiword_names.append(' '.join(current_chunk))\n            current_chunk = []\n    if len(current_chunk) > 1:\n        multiword_names.append(' '.join(current_chunk))\n\n    return list(zip(tokens, adjusted)), multiword_names\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:52:56.598257Z","iopub.execute_input":"2025-05-25T13:52:56.598655Z","iopub.status.idle":"2025-05-25T13:52:56.608832Z","shell.execute_reply.started":"2025-05-25T13:52:56.598629Z","shell.execute_reply":"2025-05-25T13:52:56.607690Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"tokens = ['Barack', 'Obama', 'and', 'Angela', 'Merkel', 'met', 'in', 'Berlin', 'for', 'the', 'G20', 'Summit', 'organized', 'by', 'the', 'United', 'Nations']\nfirst_names = {'Barack', 'Angela'}\nlast_names = {'Obama', 'Merkel'}\nstopwords = {'and', 'in', 'for', 'the', 'by'}\n\nclassified_tokens, multiword_names = name_recognition_with_context(tokens, first_names, last_names, stopwords)\n\nprint(classified_tokens)\nprint(\"Multi-word names found:\", multiword_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:53:05.870792Z","iopub.execute_input":"2025-05-25T13:53:05.871357Z","iopub.status.idle":"2025-05-25T13:53:05.877605Z","shell.execute_reply.started":"2025-05-25T13:53:05.871331Z","shell.execute_reply":"2025-05-25T13:53:05.876358Z"}},"outputs":[{"name":"stdout","text":"[('Barack', 'First Name'), ('Obama', 'Last Name'), ('and', 'Stopword'), ('Angela', 'First Name'), ('Merkel', 'Last Name'), ('met', 'Other'), ('in', 'Stopword'), ('Berlin', 'Other'), ('for', 'Stopword'), ('the', 'Stopword'), ('G20', 'Other'), ('Summit', 'Other'), ('organized', 'Other'), ('by', 'Stopword'), ('the', 'Stopword'), ('United', 'Other'), ('Nations', 'Other')]\nMulti-word names found: ['Barack Obama', 'Angela Merkel']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}